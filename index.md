# Blog Post: [[1]](#blog-post-1) [[2]](#blog-post-2) [[3]](#blog-post-3-project-proposal)

## Blog Post 1

Our team, BallmerNLP, is comprised of Nelson Liu, Mathew Luo, and Deric Pang.
Our capstone will be hosted at
[https://github.com/dericp/uw-nlp-capstone](https://github.com/dericp/uw-nlp-capstone).

There are three potential projects we are excited about.

### Alternative ELMo Training Objective

The ELMo training objective is to predict the next word given the history.
However, it's not obvious that this training objective will result in a rich
representation of the input text.  We are curious how ELMo embeddings will
change if we modify the objective to jointly predict the next N words given the
history.  Intuitively, this will force the model to learn a high-level
representation of the input that can recover more than just the next word.

Modifying the current ELMo architecture to jointly predict the next N words
should be rather straightforward. It will be tricky to perform fine-tuning
and run experiments to understand what this modified objective accomplishes.
In the best case, we will discover that modifying the ELMo training objective
to predict more words in the future improves the representations generated by
ELMo and results in performance gains on downstream tasks.

### Are Parsers Overfit to PTB?

The Penn Treebank (PTB) was first developed in 1993. Since then, it has become
_the_ standard dataset to train and evaluate parsers in English. Unfortunately,
this means that the same train, dev, and test splits have been used for many
years. We hypothesize that modern parsers may be overfitting to the PTB test
set, and we want to test this by annotating a new test set of comparable size.

Following the original PTB annotation guidelines will be extremely challenging.
It will take weeks just to read and understand the guidelines, and even more
time to become proficient in creating parse trees.  We will likely have to work
with a linguist to verify the quality of our parse trees. In the best case, we
will create a new high-quality PTB test set that will allow us to verify
whether modern parsers have overfit to PTB.

### Biasing models with Human Attention

For this task, we will first obtain datasets with annotated human attention. We
will then extend existing models to take human attention as input and use them
to bias the model. For example, Barret et. al.  regularize neural attention
with human attention.

After we train these models, we will compare them on the same datasets against
models that do not use human attention. We can then analyze the effects of
human attention.  One stretch goal for this project is to show that biasing
models with human attention can consistently improve performance across
different tasks and models.

## Blog Post 2

### Alternative ELMo Training Objective

Pros:
  * Relatively easy to implement.
  * Clear baselines to compare against.
  * Simple but interesting modification to existing techniques.

Cons:
  * Requires significant compute power.
  * Very likely that this will not give interesting results.
  * Beating the performance of BERT will be difficult.

### Biasing Models with Human Attention

Pros:
  * Interesting idea to see how human way of processing text can help NLP models.
  * Clear baselines to compare against for the end tasks.

Cons:
  * Corpora annotated with human attention usually are not labelled for NLP and
  vice versa.
  * Hard to tell if the gain is from human attention or multitasking if we deal
  with the last con by multitasking.
  
### Do PTB Parsers Generalize to the PTB?

Pros:
  * Of great importance to the NLP community (particularly those working on syntactic parsing). Past trends in NLP mostly saw datasets being constructed and used for (literal) decades---how much have we overfit in the interim?
  * Relatively straightforward to conduct the experiment, and the results are interesting regardless of the outcome.

Cons:
  * Requires lots of manual labor (manually annotating parse trees), which may be a bit boring.
  * It might be hard to run some of the older parsers (especially the non-neural ones...)

### Likely Codebases and Platforms

We will do most of our work in AllenNLP and PyTorch.

### Lecture Topic or Class Discussion

It would be fun to have a lecture on the history of the PTB, key design choices
that were made, and a general history of parsers.

## Blog Post 3: Project Proposal

Contextual word representations (CWRs) like ELMo[^fn1], GPT[^fn2], and
BERT[^fn3] have recently caused a paradigm shift in representation learning in
NLP.  By pretraining language models on massive amounts of text,
state-of-the-art results were achieved across many different tasks.

We seek to understand some observed shortcomings of CWRs---in particular, there
is evidence that while contextual word embeddings approach or outperform state
of the art on many tasks, the same embeddings perform poorly on named entity
recognition (NER).[^fn4]

### Minimum Viable Action Plan

We will develop tasks that can probe different aspects of CWRs. These tasks
will be targeted to understand why CWRs might perform poorly on NER.
Once we have develop our probing tasks, we will use them to evaluate the
different CWRs and see where they fall short compared to previous state of the
art. Since this will be an analysis project, our evaluation will boil down to
whether we are able to make a convincing argument about why CWRs perform better
on some tasks than others.

### Stretch Goals

In the case that our probing tasks are successful, we hope to explore methods
of improving CWRs such that they do not have the same observed weaknesses as
ELMo, GPT, and BERT.

### References

[^fn1]: Peters, Matthew E., et al. "Deep contextualized word representations." arXiv preprint arXiv:1802.05365 (2018).
[^fn2]: Radford, Alec, et al. "Improving language understanding by generative pre-training." URL https://s3-us-west-2. amazonaws. com/openai-assets/research-covers/languageunsupervised/language understanding paper. pdf (2018).
[^fn3]: Devlin, Jacob, et al. "Bert: Pre-training of deep bidirectional transformers for language understanding." arXiv preprint arXiv:1810.04805 (2018).
[^fn4]: Liu, Nelson F., et al. "Linguistic Knowledge and Transferability of Contextual Representations." arXiv preprint arXiv:1903.08855 (2019).
