## UW NLP Capstone: Team BallmerNLP

### Blog Post \#1

Our team, BallmerNLP, is comprised of Nelson Liu, Mathew Luo, and Deric Pang.
Our capstone will be hosted at
[https://github.com/dericp/uw-nlp-capstone](https://github.com/dericp/uw-nlp-capstone).

There are three potential projects we are excited about.

#### Alternative ELMo Training Objective

The ELMo training objective is to predict the next word given the history.
However, it's not obvious that this training objective will result in a rich
representation of the input text.  We are curious how ELMo embeddings will
change if we modify the objective to jointly predict the next N words given the
history.  Intuitively, this will force the model to learn a high-level
representation of the input that can recover more than just the next word.

Modifying the current ELMo architecture to jointly predict the next N words
should be rather straightforward. It will be tricky to perform fine-tuning
and run experiments to understand what this modified objective accomplishes.
In the best case, we will discover that modifying the ELMo training objective
to predict more words in the future improves the representations generated by
ELMo and results in performance gains on downstream tasks.

#### Are Parsers Overfit to PTB?

The Penn Treebank (PTB) was first developed in 1993. Since then, it has become
_the_ standard dataset to train and evaluate parsers in English. Unfortunately,
this means that the same train, dev, and test splits have been used for many
years. We hypothesize that modern parsers may be overfitting to the PTB test
set, and we want to test this by annotating a new test set of comparable size.

Following the original PTB annotation guidelines will be extremely challenging.
It will take weeks just to read and understand the guidelines, and even more
time to become proficient in creating parse trees.  We will likely have to work
with a linguist to verify the quality of our parse trees. In the best case, we
will create a new high-quality PTB test set that will allow us to verify
whether modern parsers have overfit to PTB.

#### Biasing models with Human Attention

For this task, we will first obtain datasets with annotated human attention. We
will then extend existing models to take human attention as input and use them
to bias the model. For example, Barret et. al.  regularize neural attention
with human attention.

After we train these models, we will compare them on the same datasets against
models that do not use human attention. We can then analyze the effects of
human attention.  One stretch goal for this project is to show that biasing
models with human attention can consistently improve performance across
different tasks and models.

### Blog Post \#2

#### Alternative ELMo Training Objective

Pros:
  * Relatively easy to implement.
  * Clear baselines to compare against.
  * Simple but interesting modification to existing techniques.

Cons:
  * Requires significant compute power.
  * Very likely that this will not give interesting results.
